hello world
Cryptography represents an important part 
of the information exchange nowadays
providing secure communications and data integrity.
There are many existing encryption algorithms
that could provide the confidentiality and integrity
data during transmission over different channels
One of the most used cryptographic algorithms is AES
Advanced Encryption Standard
It was developed in 2001 by Vincent Rijmen
and Joan Daemon, as a replacement for DES.
that became outdated and insecure
as technology advanced, mostly because
of its short key length. The AES algorithm 
is widely used in wireless security, file
encryption, SSL/TLS etc.
AES, also known by its original 
name Rijndael, is a symmetric key algorithm,
or secret-key algorithm, meaning that both
 the encryption and the decryption are
performed with the same key. 
AES 
is also a block cipher,
that uses 128-bit, 192-bit or 256-bit key
 to process 128-bit data blocks. 
 AES comes with a key expansion
algorithm, so that each encryption step
is performed using different sub-keys.
The following figure illustrates the 
process of a 128-bit AES encryption.
 The data
block and the key are represented
as 4x4 matrix,
 where each element has 1 byte. 
 Of
course, 
for key lengths of 192-bit
 or 256-bit the matrix dimension would 
 be 4x6 or 4x8. 
 The output of each step 
 represents an input for the following step.
 The initial key passes
 through a series of
 transformations, in 10 different rounds
 (for AES 128). 
 For AES 192 and AES 256 there
 are 8, respectively 7 rounds.
 The subkey
obtained in every round 
is used in the Add round key 
step from the encryption.
Parallel implementations come with 
a great advantage compared to the conventional
ones: high speedup.
 This is also the case for cryptographic 
 algorithms, that
can provide the same efficiency
 in terms of security, but a lot faster.
 In order to compare further 
 the performance of the
 AES implementation on the
custom accelerator, I compiled
 a list of papers in which different
 methods of parallelization,
 on different platforms, 
 are used in order to achieve 
 a great speedup for
AES encryption.
This paper
 presents a high-throughput
 bitsliced implementation of AES,
 using a
technique that redesigns all the
 stages of the algorithm. They 
 perform some optimizations
like input rearrangement for Shift
 Rows phase, replacing byte-wise operations
with registers shifts or changing
the S-box logic circuit in order to process up
to 32 blocks of 128-bit input data at
 the same time. The hardware platforms are 6
different CUDA-enabled GPUs.
The implementation eliminates the
 computationally intensive 
 operations in all
the stages and enables each 
CUDA thread to process 32 chunks of 128-bit input data
simultaneously. Also, the 
data representation is changed
 from row-major to columnmajor
in order to increase the performance.
The row-major means that each
 128-bit chunk of data is
 stored in four 32-bit registers.
In the new column-major representation,
 to store 32 blocks of input data,
128x32-bit registers are needed.
 The difference is that
 instead of holding first bits of
data in the first register,
 it stores the least significant 
 bits from all the 32 chunks of
128-bit data. To summarize,
 each register stores bits that
 have an identical position
from all the 32 data 
blocks in the new column-major 
approach. In this manner, each
CUDA thread processes 32 
chunks of 128-bit data.
An example is in figure 2.1,
 where R states for registers
 and D states for blocks of
data.
Substitute bytes
Normally, the S-box
 lookup table takes as input
 8 bits at a time, so a data block is
read from 8 registers from 
the total of 128 registers for 16 times.
 Substitute bytes
stage is modified such that
 instead of this approach, the 
 registers where each block
is stored (R0, R1, R2, . . . .R127)
 are passed into the S-box logic
 circuit 8 registers at a
time and in this way, 32 chunks
 of data are operated in parallel.
Mix Columns step
The data representation in this 
step is also changed. Instead 
of having each element
representing 8 bits from 
a single data chunk,
 it stores now bits from the same position
of 8 registers from 
32x128-bit data chunks.
6 Chapter 2. AES 
parallelization related projects
FIGURE 2.1: Data 
row-major representation
 (Left) vs. column-major
representation (Right).
 Source [7]
Shift Rows step
Based on the described 
data representation,
 Shift Rows is implemented by register
shift and swapping 
instead of the costly Byte shift and swapping.
Add Round Key step
This step is also 
different. The main 
idea is that instead of 
applying the round key
to all of the 32 data chunks 
in parallel, each roun
d key is expanded into 128 registers
and then is XORed with 
the 128 registers from the Mix Columns stage.
AES can have multiple 
modes of operation: ECB
 (electronic code book), CBC
(cipher block chaining)
, CFB (cipher feedback),
 OFB (output feedback) and CTR
(counter). They 
implemented ECB and 
CTR modes. For the ECB mode, the input
text is divided intro 128-bit
 blocks. Every block is 
 then encrypted with the same
key. In the CTR mode, a
 counter is encrypted using the same key.
 The value of the
counter depends on the i
nput block number. For block 1,
 a counter is encrypted. For
block 2, the previous 
counter + 1 is encrypted, and
 so on. The encryption is then
XORed with the correspo
nding plaintext.
Here are the results:
FIGURE 2.2: Performance
 comparison for ECB AES encryption on different
GPU platforms . Source [7]
2.1. “Fast AES Implementation:
 A High-throughput Bitsliced Approach”-2019
(Source [7])
7
FIGURE 2.3: Performance 
comparison for CTR AES encryption on
different GPU platforms . 
Source [7]
The best performance was
 obtained in both cases using Nvidia
 Tesla V100 (maximum
1478.42 Gbps). This work is compared
 to other related projects, 
 where the
results are much smaller,
 for example maximum 605.9 
 Gbps obtained in 2017 on a
P100 GPU.
8 Chapter 2. AES 
parallelization related projects
2.2 “AES Hardware Accelerator
 on FPGA with Improved Throughput
and Resource Efficiency”- 2017
 (Source [4])
This paper presents a
 new solution for 128-bit AES
 optimization, by customizing
resources in FPGA and improving
 the pipelining efficiency.
 Memory partitioning is
used to allow read and write
 parallel operations. 
 Other technique is sub-pipelining,
that determines the operations
 to pe performed in one clock 
 cycle, for a frequency
of 813MHz. The design is
 implemented on FPGAs-XC5VLX85,
 XC6VLX240T, and
XC7VX690T devices.
The main issue that was 
slowing down the computation
 was the access of the
data and the key from 
memory. The encryption 
in pipelined so that each 
round represents
a stage.
FIGURE 2.4: AES pipelined 
implementation. Source [4]
In order to improve this
 pipelining, the memory 
 is partitioned into multiple
banks, to allow accessing 
in just one clock cycle. 
This is also possible because of the
proposed design that has 
every round of
 the algorithm also pipelined. And more,
each operation of the AES
 is sub-pipelined by
 adding registers between its steps.
The next figure illustrates 
the overall idea.
FIGURE 2.5: One round 
pipelined implementation.
 Source [4]
Each round’s steps are a
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
hello world Cryptography represents an important part of the information exchange nowadays providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity data during transmission over different channels One of the most used cryptographic algorithms is AES Advanced Encryption Standard It was developed in 2001 by Vincent Rijmen and Joan Daemon, as a replacement for DES. that became outdated and insecure as technology advanced, mostly because of its short key length. The AES algorithm  is widely used in wireless security, file encryption, SSL/TLS etc. AES, also known by its original  name Rijndael, is a symmetric key algorithm, or secret-key algorithm, meaning that both the encryption and the decryption are performed with the same key.  AES  is also a block  cipher, that uses 128-bit, 192-bit or 256-bit key  to process 128-bit data blocks.   AES comes with a key expansion algorithm, so that each encryption step is performed using different sub-keys. The following figure illustrates the  process of a 128-bit AES encryption.  The data block and the key are represented as 4x4 matrix,  where each element has 1 byte.   Of course,  for key lengths of 192-bit  or 256-bit the matrix dimension would   be 4x6 or 4x8.   The output of each step   represents an input for the following step.  The initial key passes  through a series of  transformations, in 10 different rounds (for AES 128).   For AES 192 and AES 256 there  are 8, respectively 7 rounds.  The subkey obtained in every round  is used in the Add round key  step from the encryption. Parallel implementations come with  a great advantage compared to the conventional ones: high speedup.  This is also the case for cryptographic   algorithms, that can provide the same efficiency  in terms of security, but a lot faster.  In order to compare further   the performance of the  AES implementation on the custom accelerator, I compiled  a list of papers in which different  methods of parallelization, The device runs a code called kernel, and the threads are created when a host invokes a kernel. Thread blocks are formed and assigned to an SM that will run them. The AES subkey generation is done at the host, that copies them to a memory with read only access for the threads and the input data to a global memory. Next, it invokes the kernel and the thread from the same CUDA block will encrypt consecutive data blocks. Each thread communicates to another from the same block using a shared memory. When the encryption is done, they move the data to the global memory. As results, running times for MPI implementation with 8 cores and OpenMP implementation are similar. Running times increase linearly with the size of the input data, but they decrease with increasing the number of cores for MPI. The CUDA implementation was the best in terms of time and speed – up. On a GPU, it took about 1 second to encrypt 255 MB of data and with the others implementation the minimum obtained time was 18 seconds (for MPI with 32 cores). The speed – up is significant higher using CUDA, about 500, compared to 30, in the other situations.In this approach, an AES algorithm is also implemented on GPU by parallelizing each step of the encryption using Compute Unified Device Architecture (CUDA). This leads to a speedup factor of 61.36x on the multicore heterogeneous system. The GPU contains multiprocessors, each one having distinctive stream processors (SPs), as described in the previous article. Each multiprocessor has a shared memory. There is also an off-chip memory, containing surface, steady, global and local memory. As mentioned, the AES algorithm includes a set of operations: Key Expansion, AddRoundKey, Substitution (SubByte), Rotation (ShiftRows) and MixColumn. In this implementation, the Key expansion is executed on the CPU, and the remaining steps are performed on the GPU using CUDA. Each step in the AES encryption is implemented with separate GPU kernel which launches n blocks, There was a sequential encryption implemented on Intel Core i7-4790 CPU and a parallel one on the GPU of NVIDIA Tesla K40 consisting of 2880 cores (15 Multiprocessors, 192 cores each). The results showed that the speedup is increasing as the data size increases, achieving an execution time of 61.36x smaller on GPU than on CPU for 256 KB. Implementing parallelism for the SIMD architecture of the multiprocessors in the GPU proved to achieve a great performance. This paper presents a parallel architecture developed using FPGA, by showing a method of achieving maximum utilization of its logic cells and I/O resources. They compare this implementation to the conventional pipeline architectures for symmetric cryptographic algorithms like AES and DES. They use Virtex-II Pro FPGAs for this approach. The proposal is based on the idea that pipelined architectures require a large amount of silicon area for the implementation of the block ciphers. But parallel blocks allow more flexibility when designing an encryption system, because they are smaller than pipelined blocks and offer a greater performance by using a number of n parallel blocks in the same area. Although, the parallel encryption blocks have an area disadvantage with respect to the pipelined architecture because each individual block has its own key, so the hardware is duplicated (see the next picture). But this also increase the security. The Data Encryption Standard (DES) is a symmetric algorithm that uses a 56-bit key and operates on 64-bit blocks of data. The basic operations of DES include permutations, compressions, expansions, and shifts using 32-bit operands. The proposed architecture includes 17 separate parallel DES or 3DES blocks. Some functions are just once implemented, so the same hardware is reused 16 times, leading to a smaller area and a high-throughput. The throughput is calculated as the average of total plain text, in a number of bytes, divided by the average encryption time. They obtained values up to 9 Gbps for this implementation, and also high security due to the additional keys from each block. For the AES algorithm this design uses a data input length of 128 bits with a key length of 128 bits. Basic operations include byte substitutions, independent row byte shifts, column Galois field multiplications, and key additions. The design minimizes hardware duplication, implementing 10 parallel blocks and the obtained throughput is up to 19 Gbps. With this implementation, they obtained great results in terms of area optimization and speed, parallelizing multiple blocks with higher capability of encryption and security than the conventional pipelined architectures. D. “SIMD Acceleration of Modular Arithmetic on Contemporary Embedded Platforms” by Krishna Chaitanya Pabbuleti, Deepak Hanamant Mane, Avinash Desai, Curt Albert and Patrick Schaumon (Source [7]) Changing the direction towards public key cryptography, this paper describes the Elliptic Curve Cryptography (ECC) algorithm on various processors. ECC is frequent used in embedded implementations because of its small keys size compared to other asymmetric protocols. Although, the computation is complicated: point additions and doublings on elliptic curves over finite fields. The most time consuming operation is the modular multiplication. Their proposal is to demonstrate the acceleration of this operation on two different hardware platforms supporting SIMD instructions, Qualcomm Scorpion and Intel Atom processor. The first one is Qualcomm Snapdragon APQ8060, that features a dual CPU (Scorpion) architecture, running up to 1.7 GHz each and two VeNum (NEON) 128-bit SIMD multimedia coprocessors. It is similar to ARM Cortex-A8 and ARM Cortex-A9 CPUs. The NEON architecture has many vector registers, thus it reduces the number of loads and stores from memory. The 128-bit arithmetic unit can perform four 32-bit operations in each cycle. Intel Atom N2800 processor has a power comparable to a RISC architecture, with a x86 instruction set.  tography - Kimmo Jarvinen, Jorma Skytta;
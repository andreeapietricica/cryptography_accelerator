Cryptography represents an important part of the information exchange nowadays, providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity of data during transmission over different channels. Parallel implementations come with a great advantage compared to the conventional ones: high speedup. This is also the case for cryptographic algorithms, that can provide the same efficiency in terms of security, but a lot faster. In order to compare further the performance of the AES implementation on the custom accelerator, I compiled a list of papers in which different methods of parallelization, on different platforms, are used in order to achieve a great speedup for AES encryption. This paper presents a high-throughput bitsliced implementation of AES, using a technique that redesigns all the stages of the algorithm. They perform some optimizations like input rearrangement for Shift Rows phase, replacing byte-wise operations with registers shifts or changing the S-box logic circuit in order to process up to 32 blocks of 128-bit input data at the same time. The hardware platforms are 6 different CUDA-enabled GPUs. The implementation eliminates the computationally intensive operations in all the stages and enables each CUDA thread to process 32 chunks of 128-bit input data simultaneously. Also, the data representation is changed from row-major to column-major in order to increase the performance. The row-major means that each 128-bit chunk of data is stored in four 32-bit registers. In the new column-major representation, to store 32 blocks of input data, 128x32-bit registers are needed. The difference is that instead of holding first bits of data in the first register, it stores the least significant bits from all the 32 chunks of 128-bit data. To summarize, each register stores bits that have an identical position from all the 32 data blocks in the new column-major approach. In this manner, each CUDA thread processes 32 chunks of 128-bit data.AES can have multiple modes of operation: ECB (electronic code book), CBC (cipher block chaining), CFB (cipher feedback), OFB (output feedback) and CTR (counter). They implemented ECB and CTR modes. For the ECB mode, the input text is divided intro 128-bit blocks. Every block is then encrypted with the same key. In the CTR mode, a counter is encrypted using the same key. The value of the counter depends on the input block number. For block 1, a counter is encrypted. For block 2, the previous counter + 1 is encrypted, and so on. The encryption is then XORed with the corresponding plaintext. This paper presents a new solution for 128-bit AES optimization, by customizing resources in FPGA and improving the pipelining efficiency. Memory partitioning is used to allow read and write parallel operations. Other technique is sub-pipelining, that determines the operations to pe performed in one clock cycle, for a frequency of 813MHz. The design is implemented on FPGAs-XC5VLX85, XC6VLX240T, and XC7VX690T devices. In order to improve this pipelining, the memory is partitioned into multiple
banks, to allow accessing in just one clock cycle. This is also possible because of the proposed design that has every round of the algorithm also pipelined. And more, each operation of the AES is sub-pipelined by adding registers between its steps.
The next figure illustrates the overall idea. In the substitute bytes stage, each byte of data is replaced with a value from S-box and, as consequence, this is also pipelined and unrolled. More, the Substitute Bytes step can be merged with Shift Rows step, because only one clock cycle is needed to perform both the replacement and the shifting of the result.
Mix Columns stage sub-operations are also unrolled and pipelined. For the Add Round Key stage pipelining is not necessary, because of the memory partitioning that allows multiple ports reading the key, so that it will be XORed with the data array within one clock cycle. The best critical path delay of the design is 1.23 ns and the maximum frequency that allowed maintaining one clock per cycle is 813 MHz. The overall latency is 58
clock cycles for 128-bit input plaintext and the best achieved throughput is 104.06 Gbps. A comparison between all the target platforms can be seen in the next figure.
Cryptography represents an important part of the information exchange nowadays, providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity of data during transmission over different channels. Parallel implementations come with a great advantage compared to the conventional ones: high speedup. This is also the case for cryptographic algorithms, that can provide the same efficiency in terms of security, but a lot faster. In order to compare further the performance of the AES implementation on the custom accelerator, I compiled a list of papers in which different methods of parallelization, on different platforms, are used in order to achieve a great speedup for AES encryption. This paper presents a high-throughput bitsliced implementation of AES, using a technique that redesigns all the stages of the algorithm. They perform some optimizations like input rearrangement for Shift Rows phase, replacing byte-wise operations with registers shifts or changing the S-box logic circuit in order to process up to 32 blocks of 128-bit input data at the same time. The hardware platforms are 6 different CUDA-enabled GPUs. The implementation eliminates the computationally intensive operations in all the stages and enables each CUDA thread to process 32 chunks of 128-bit input data simultaneously. Also, the data representation is changed from row-major to column-major in order to increase the performance. The row-major means that each 128-bit chunk of data is stored in four 32-bit registers. In the new column-major representation, to store 32 blocks of input data, 128x32-bit registers are needed. The difference is that instead of holding first bits of data in the first register, it stores the least significant bits from all the 32 chunks of 128-bit data. To summarize, each register stores bits that have an identical position from all the 32 data blocks in the new column-major approach. In this manner, each CUDA thread processes 32 chunks of 128-bit data.AES can have multiple modes of operation: ECB (electronic code book), CBC (cipher block chaining), CFB (cipher feedback), OFB (output feedback) and CTR (counter). They implemented ECB and CTR modes. For the ECB mode, the input text is divided intro 128-bit blocks. Every block is then encrypted with the same key. In the CTR mode, a counter is encrypted using the same key. The value of the counter depends on the input block number. For block 1, a counter is encrypted. For block 2, the previous counter + 1 is encrypted, and so on. The encryption is then XORed with the corresponding plaintext. This paper presents a new solution for 128-bit AES optimization, by customizing resources in FPGA and improving the pipelining efficiency. Memory partitioning is used to allow read and write parallel operations. Other technique is sub-pipelining, that determines the operations to pe performed in one clock cycle, for a frequency of 813MHz. The design is implemented on FPGAs-XC5VLX85, XC6VLX240T, and XC7VX690T devices. In order to improve this pipelining, the memory is partitioned into multiple
banks, to allow accessing in just one clock cycle. This is also possible because of the proposed design that has every round of the algorithm also pipelined. And more, each operation of the AES is sub-pipelined by adding registers between its steps.
The next figure illustrates the overall idea. In the substitute bytes stage, each byte of data is replaced with a value from S-box and, as consequence, this is also pipelined and unrolled. More, the Substitute Bytes step can be merged with Shift Rows step, because only one clock cycle is needed to perform both the replacement and the shifting of the result.
Mix Columns stage sub-operations are also unrolled and pipelined. For the Add Round Key stage pipelining is not necessary, because of the memory partitioning that allows multiple ports reading the key, so that it will be XORed with the data array within one clock cycle. The best critical path delay of the design is 1.23 ns and the maximum frequency that allowed maintaining one clock per cycle is 813 MHz. The overall latency is 58
clock cycles for 128-bit input plaintext and the best achieved throughput is 104.06 Gbps. A comparison between all the target platforms can be seen in the next figure.
Cryptography represents an important part of the information exchange nowadays, providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity of data during transmission over different channels. Parallel implementations come with a great advantage compared to the conventional ones: high speedup. This is also the case for cryptographic algorithms, that can provide the same efficiency in terms of security, but a lot faster. In order to compare further the performance of the AES implementation on the custom accelerator, I compiled a list of papers in which different methods of parallelization, on different platforms, are used in order to achieve a great speedup for AES encryption. This paper presents a high-throughput bitsliced implementation of AES, using a technique that redesigns all the stages of the algorithm. They perform some optimizations like input rearrangement for Shift Rows phase, replacing byte-wise operations with registers shifts or changing the S-box logic circuit in order to process up to 32 blocks of 128-bit input data at the same time. The hardware platforms are 6 different CUDA-enabled GPUs. The implementation eliminates the computationally intensive operations in all the stages and enables each CUDA thread to process 32 chunks of 128-bit input data simultaneously. Also, the data representation is changed from row-major to column-major in order to increase the performance. The row-major means that each 128-bit chunk of data is stored in four 32-bit registers. In the new column-major representation, to store 32 blocks of input data, 128x32-bit registers are needed. The difference is that instead of holding first bits of data in the first register, it stores the least significant bits from all the 32 chunks of 128-bit data. To summarize, each register stores bits that have an identical position from all the 32 data blocks in the new column-major approach. In this manner, each CUDA thread processes 32 chunks of 128-bit data.AES can have multiple modes of operation: ECB (electronic code book), CBC (cipher block chaining), CFB (cipher feedback), OFB (output feedback) and CTR (counter). They implemented ECB and CTR modes. For the ECB mode, the input text is divided intro 128-bit blocks. Every block is then encrypted with the same key. In the CTR mode, a counter is encrypted using the same key. The value of the counter depends on the input block number. For block 1, a counter is encrypted. For block 2, the previous counter + 1 is encrypted, and so on. The encryption is then XORed with the corresponding plaintext. This paper presents a new solution for 128-bit AES optimization, by customizing resources in FPGA and improving the pipelining efficiency. Memory partitioning is used to allow read and write parallel operations. Other technique is sub-pipelining, that determines the operations to pe performed in one clock cycle, for a frequency of 813MHz. The design is implemented on FPGAs-XC5VLX85, XC6VLX240T, and XC7VX690T devices. In order to improve this pipelining, the memory is partitioned into multiple
banks, to allow accessing in just one clock cycle. This is also possible because of the proposed design that has every round of the algorithm also pipelined. And more, each operation of the AES is sub-pipelined by adding registers between its steps.
The next figure illustrates the overall idea. In the substitute bytes stage, each byte of data is replaced with a value from S-box and, as consequence, this is also pipelined and unrolled. More, the Substitute Bytes step can be merged with Shift Rows step, because only one clock cycle is needed to perform both the replacement and the shifting of the result.
Mix Columns stage sub-operations are also unrolled and pipelined. For the Add Round Key stage pipelining is not necessary, because of the memory partitioning that allows multiple ports reading the key, so that it will be XORed with the data array within one clock cycle. The best critical path delay of the design is 1.23 ns and the maximum frequency that allowed maintaining one clock per cycle is 813 MHz. The overall latency is 58
clock cycles for 128-bit input plaintext and the best achieved throughput is 104.06 Gbps. A comparison between all the target platforms can be seen in the next figure.
Cryptography represents an important part of the information exchange nowadays, providing secure communications and data integrity. There are many existing encryption algorithms that could provide the confidentiality and integrity of data during transmission over different channels. Parallel implementations come with a great advantage compared to the conventional ones: high speedup. This is also the case for cryptographic algorithms, that can provide the same efficiency in terms of security, but a lot faster. In order to compare further the performance of the AES implementation on the custom accelerator, I compiled a list of papers in which different methods of parallelization, on different platforms, are used in order to achieve a great speedup for AES encryption. This paper presents a high-throughput bitsliced implementation of AES, using a technique that redesigns all the stages of the algorithm. They perform some optimizations like input rearrangement for Shift Rows phase, replacing byte-wise operations with registers shifts or changing the S-box logic circuit in order to process up to 32 blocks of 128-bit input data at the same time. The hardware platforms are 6 different CUDA-enabled GPUs. The implementation eliminates the computationally intensive operations in all the stages and enables each CUDA thread to process 32 chunks of 128-bit input data simultaneously. Also, the data representation is changed from row-major to column-major in order to increase the performance. The row-major means that each 128-bit chunk of data is stored in four 32-bit registers. In the new column-major representation, to store 32 blocks of input data, 128x32-bit registers are needed. The difference is that instead of holding first bits of data in the first register, it stores the least significant bits from all the 32 chunks of 128-bit data. To summarize, each register stores bits that have an identical position from all the 32 data blocks in the new column-major approach. In this manner, each CUDA thread processes 32 chunks of 128-bit data.AES can have multiple modes of operation: ECB (electronic code book), CBC (cipher block chaining), CFB (cipher feedback), OFB (output feedback) and CTR (counter). They implemented ECB and CTR modes. For the ECB mode, the input text is divided intro 128-bit blocks. Every block is then encrypted with the same key. In the CTR mode, a counter is encrypted using the same key. The value of the counter depends on the input block number. For block 1, a counter is encrypted. For block 2, the previous counter + 1 is encrypted, and so on. The encryption is then XORed with the corresponding plaintext. This paper presents a new solution for 128-bit AES optimization, by customizing resources in FPGA and improving the pipelining efficiency. Memory partitioning is used to allow read and write parallel operations. Other technique is sub-pipelining, that determines the operations to pe performed in one clock cycle, for a frequency of 813MHz. The design is implemented on FPGAs-XC5VLX85, XC6VLX240T, and XC7VX690T devices. In order to improve this pipelining, the memory is partitioned into multiple
banks, to allow accessing in just one clock cycle. This is also possible because of the proposed design that has every round of the algorithm also pipelined. And more, each operation of the AES is sub-pipelined by adding registers between its steps.
The next figure illustrates the overall idea. In the substitute bytes stage, each byte of data is replaced with a value from S-box and, as consequence, this is also pipelined and unrolled. More, the Substitute Bytes step can be merged with Shift Rows step, because only one clock cycle is needed to perform both the replacement and the shifting of the result.
Mix Columns stage sub-operations are also unrolled and pipelined. For the Add Round Key stage pipelining is not necessary, because of the memory partitioning that allows multiple ports reading the key, so that it will be XORed with the data array within one clock cycle. The best critical path delay of the design is 1.23 ns and the maximum frequency that allowed maintaining one clock per cycle is 813 MHz. The overall latency is 58
clock cycles for 128-bit input plaintext and the best achieved throughput is 104.06 Gbps. A comparison between all the target platforms can be seen in the next figure.